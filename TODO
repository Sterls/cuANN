09.12.2015
TODO:

        1. Create a "Test" function which takes as argumnt a "*.test" file.
           Run propagation for each input, collect sq_error and report back MSE.

        2. Create (de)serialisation for class ann: 
           Saving and Loading (Using BOOST) of a Trained network.

        3. Implement Resilient-Back-Propagation

        4. Create a more examples, using data-sets: `diabetes`,`gene`,`mushroom`,`soybean`,`thyroid`
           It is important that I have a Deep Network working BEFORE the end of December!!!

        5. It would be nice to be able to save on a file the actual recorded MSE's.

        6. OPTIMIZE: the `trainer` class has serious problems: too many copies and allocations.
                     What I need is a flat (and more elegant) way of fw_propagating, which is spamming `cudaMemcpy` and `cudaMemaloc`
                     In order to do this, I need to rethink my `trainer::fw_propagate` seriously.

        7. I should enforce `const corectness` in kernels whenever and wherever possible.

NOTE: Profiling using nvprof was revealing: most time is spent allocating and copying memory.
      This needs to be addressed and fixed.
